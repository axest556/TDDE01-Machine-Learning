setwd("~/TDDE01/tdde01-machinelearning/Labs/lab2")
fit_default <- tree(as.factor(y) ~ ., data = train)
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### DIVIDE THE DATA ####
# Load the data into a variable
data <- read.csv("bank-full.csv", header = T, sep=";") #read.csv2 takes the separator as ; as defult
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 50% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 25% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#### Task 2.2 ####
#Default fit
fit_default <- tree(as.factor(y) ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class")
valid_pred_default <- predict(fit_default, valid, type = "class")
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train$y <- as.factor(train$y)
# Default fit
fit_default <- tree(y ~ ., data = train)
# Default fit
fit_default <- tree(y ~ ., data = train)
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### DIVIDE THE DATA ####
# Load the data into a variable
data <- read.csv("bank-full.csv", header = T, sep=";", stringsAsFactors = TRUE) #read.csv2 takes the separator as ; as defult
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 50% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 25% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#
#### Task 2.2 ####
train$y <- as.factor(train$y)
# Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class")
valid_pred_default <- predict(fit_default, valid, type = "class")
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
install.packages("tree")
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### DIVIDE THE DATA ####
# Load the data into a variable
data <- read.csv("bank-full.csv", header = T, sep=";", stringsAsFactors = TRUE) #read.csv2 takes the separator as ; as defult
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 50% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 25% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#
#### Task 2.2 ####
train$y <- as.factor(train$y)
# Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class")
valid_pred_default <- predict(fit_default, valid, type = "class")
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Load the data into a variable
data <- read.csv("bank-full.csv", header = T, sep=";") #read.csv2 takes the separator as ; as defult
# Do not use stringAsFactor = TRUE above ...?
data <- data[, !names(data) %in% c("duration")]
convert_chr_to_factor <- function(data) {
# Loop through each column in the dataset
for (col_name in names(data)) {
# Check if the column is of type character
if (is.character(data[[col_name]])) {
# Convert character column to factor
data[[col_name]] <- as.factor(data[[col_name]])
}
}
return(data)
}
# Example usage
data <- convert_chr_to_factor(data)
View(data)
View(data)
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### DIVIDE THE DATA ####
# Load the data into a variable
data <- read.csv("bank-full.csv", header = T, sep=";") #read.csv2 takes the separator as ; as defult
# Do not use stringAsFactor = TRUE above ...?
data <- data[, !names(data) %in% c("duration")]
convert_chr_to_factor <- function(data) {
# Loop through each column in the dataset
for (col_name in names(data)) {
# Check if the column is of type character
if (is.character(data[[col_name]])) {
# Convert character column to factor
data[[col_name]] <- as.factor(data[[col_name]])
}
}
return(data)
}
# Example usage
data <- convert_chr_to_factor(data)
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 50% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 25% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#
#### Task 2.2 ####
train$y <- as.factor(train$y)
# Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class")
valid_pred_default <- predict(fit_default, valid, type = "class")
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Pre3diction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
valid_pred_default
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Model 2 -
# Model 2 - Smallest allowed node size = 7000
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(minsize = 7000))  # Set the minimum node size to 7000
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### TASK 2.1 ####
# Load the data into a variable
data <- read.csv("bank-full.csv",
header = T, sep=";",
stringsAsFactors = TRUE) # Note: read.csv2 takes the separator as ; as default
# Remove duration column from data set
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 40% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 30% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#### Task 2.2 ####
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Model 2 - Smallest allowed node size = 7000
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(minsize = 7000))  # Set the minimum node size to 7000
n_train <- dim(train)[1]
n
n_train <- dim(train)[1]
n_train
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, minsize = 7000))  # Set the minimum node size to 7000
train_pred_7000 <- predict(fit_7000, train, type = "class") # Prediction on train data
valid_pred_7000 <- predict(fit_7000, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_7000 <- mean(train_pred_7000 != train$y) # 0.1142446
valid_mis_7000 <- mean(valid_pred_7000 != valid$y) # 0.1207697
#### Task 2.2 ####
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, minsize = 7000))  # Set the minimum node size to 7000
train_pred_7000 <- predict(fit_7000, train, type = "class") # Prediction on train data
valid_pred_7000 <- predict(fit_7000, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_7000 <- mean(train_pred_7000 != train$y) # 0.1142446
valid_mis_7000 <- mean(valid_pred_7000 != valid$y) # 0.1207697
train_mis_7000
valid_mis_7000
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### TASK 2.1 ####
# Load the data into a variable
data <- read.csv("bank-full.csv",
header = T, sep=";",
stringsAsFactors = TRUE) # Note: read.csv2 takes the separator as ; as default
# Remove duration column from data set
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 40% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 30% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#### Task 2.2 ####
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, minsize = 7000))  # Set the minimum node size to 7000
train_pred_7000 <- predict(fit_7000, train, type = "class") # Prediction on train data
valid_pred_7000 <- predict(fit_7000, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_7000 <- mean(train_pred_7000 != train$y) # 0.1142446
valid_mis_7000 <- mean(valid_pred_7000 != valid$y) # 0.1207697
train_mis_7000
valid_mis_7000
#### INSTALL NECESSARY PACKAGES ####
install.packages("tree")
library(tree)
#### TASK 2.1 ####
# Load the data into a variable
data <- read.csv("bank-full.csv",
header = T, sep=";",
stringsAsFactors = TRUE) # Note: read.csv2 takes the separator as ; as default
# Remove duration column from data set
data <- data[, !names(data) %in% c("duration")]
# Get the number of rows in the dataset
n <- dim(data)[1]
# Set a random seed for reproducibility
set.seed(12345)
# Partition 40% of the data for the training set
id <- sample(1:n, floor(n * 0.4))
train <- data[id, ]
# Partition 30% of the data for the validation set
id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n * 0.3))
valid <- data[id2, ]
# Use the rest for the test set
id3 <- setdiff(id1, id2)
test <- data[id3, ]
#### Task 2.2 ####
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
# Visualize both trees
plot(fit_default)
text(fit_default, pretty = 0)
plot(fit_7000)
text(fit_7000, pretty = 0)
# Visualize both trees
plot(fit_default)
text(fit_default, pretty = 0)
plot(fit_7000)
text(fit_7000, pretty = 0)
# Visualize both trees
plot(fit_default)
# Visualize both trees
plot(fit_default)
text(fit_default, pretty = 0)
plot(fit_7000)
text(fit_7000, pretty = 0)
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
# Model 1 - Default fit
fit_default <- tree(y ~ ., data = train)
train_pred_default <- predict(fit_default, train, type = "class") # Prediction on train data
valid_pred_default <- predict(fit_default, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_default <- mean(train_pred_default != train$y) # 0.1142446
valid_mis_default <- mean(valid_pred_default != valid$y) # 0.1207697
train_mis_default
valid_mis_default
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
fit_7000 <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, minsize = 7000))  # Set the minimum node size to 7000
train_pred_7000 <- predict(fit_7000, train, type = "class") # Prediction on train data
valid_pred_7000 <- predict(fit_7000, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_7000 <- mean(train_pred_7000 != train$y) # 0.1142446
valid_mis_7000 <- mean(valid_pred_7000 != valid$y) # 0.1207697
train_mis_7000
valid_mis_7000
train_mis_7000
valid_mis_7000
train_mis_default
valid_mis_default
plot(fit_min_node)
train_pred_min_node <- predict(fit_min_node, train, type = "class") # Prediction on train data
# Fit the model with a smallest allowed node size of 7000
fit_min_node <- tree(y ~ .,
data = train,
control = tree.control
# Model 2 - Smallest allowed node size = 7000
# This means that
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
# Model 2 - Smallest allowed node size = 7000
n_train <- dim(train)[1] # Nr of obeservations (rows) in train data
# Fit the model with a smallest allowed node size of 7000
fit_min_node <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, minsize = 7000))  # Set the minimum node size to 7000
train_pred_min_node <- predict(fit_min_node, train, type = "class") # Prediction on train data
valid_pred_min_node <- predict(fit_min_node, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_min_node <- mean(train_pred_min_node != train$y) # 0.1048441
valid_mis_min_node <- mean(valid_pred_min_node != valid$y) # 0.1092679
plot(fit_min_node)
text(fit_min_node, pretty = 0)
plot(fit_min_node)
text(fit_min_node, pretty = 0)
summary(fit_min_node)
summary(fit_default)
# Fit the tree model with a minimum deviance of 0.0005
fit_min_dev <- tree(y ~ .,
data = train,
control = tree.control(nobs = n_train, mindev = 0.0005))
train_pred_min_dev <- predict(fit_min_dev, train, type = "class") # Prediction on train data
valid_pred_min_dev <- predict(fit_min_dev, valid, type = "class") # Prediction on validation data
# Calculate misclassification errors
train_mis_min_dev <- mean(train_pred_min_dev != train$y) # 0.1048441
valid_mis_min_dev <- mean(valid_pred_min_dev != valid$y) # 0.1092679
train_mis_min_dev
valid_mis_min_dev
summary(fit_min_dev)
# Visualize all trees
plot(fit_default)
text(fit_default, pretty = 0)
summary(fit_default)
plot(fit_min_node)
text(fit_min_node, pretty = 0)
summary(fit_min_node)
plot(fit_min_dev)
text(fit_min_dev, pretty = 0)
summary(fit_min_dev)
# Visualize all trees
plot(fit_default)
text(fit_default, pretty = 0)
summary(fit_default)
plot(fit_min_node)
text(fit_min_node, pretty = 0)
summary(fit_min_node)
plot(fit_min_dev)
text(fit_min_dev, pretty = 0)
summary(fit_min_dev)
