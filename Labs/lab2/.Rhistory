# Most important variables for decision making in this tree (top nodes):
# poutcome, month, contact
#### TASK 2.4 - Confusion Matrix, Accuracy & F1 Score ####
# Confusion matrix based on test data
pred_test <- predict(optimalTree, newdata = test, type = "class") # Predictions on test set
confusion_matrix <- table(True = test$y, Predicted = pred_test)
print(confusion_matrix)
# Compute necessary variables
n_test <- dim(test)[1] # Nr of obeservations (rows) in train data
TP <- confusion_matrix["yes", "yes"] # True Positive. 214
TN <- confusion_matrix["no", "no"] # True Negative.   11872
FP <- confusion_matrix["no", "yes"] # False Positive  107
FN <- confusion_matrix["yes", "no"] # False Negative  1371
# Accuracy based on test data = (TP + TN) / n
accuracy <- (TP + TN) / n_test
accuracy # 0.8910351
# Precision, Recall, and F1 Score
precision <- TP / (TP + FP) # 0.6666667
recall <- TP / (TP + FN) # = True Positive Rates = sensitivity = recall = 0.1350157
F1 <- (2 * precision * recall) / (precision + recall)
F1 # 0.224554
# Accuracy does not take imbalanced classes into account, but F1 score does
# Imbalanced classes meaning very large number of 1 and very small number of 0
sum(test$y == "yes") # 1585 cases
sum(test$y == "no")  # 11979 cases
# F1 is preferre due to the class imbalance.
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
summary(fit_tree_with_loss)
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix)
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
plot(fit_tree_with_loss)
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
# Visualize
plot(fit_tree_with_loss)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
# Visualize
plot(fit_tree_with_loss)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = test, method = "class",
parms = list(loss = loss_matrix))
# Visualize
plot(fit_tree_with_loss)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
# Visualize
plot(fit_tree_with_loss)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
summary(fit_tree_with_loss)
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix)
pred_test_loss
sum(pred_test_loss$y == "no")
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
pred_test_loss
sum(pred_test_loss$y == "no")
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
sum(pred_test_loss$y == "no")
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
sum(pred_test_loss$y == "no")
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix)
summary(fit_tree_with_loss)
# Custom Loss Matrix: TP=0, FP=1,
loss_matrix <- matrix(c(0, 1, 5, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix: TP=0, FP=1,
loss_matrix <- matrix(c(0, 1, 5, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
summary(fit_tree_with_loss)
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix: TP=0, FP=1,
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
summary(fit_tree_with_loss)
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix)
plot(fit_tree_with_loss)
summary(fit_tree_with_loss)
#### TASK 2.5 - Decision Tree Classification with Loss Matrix ####
# A loss matrix assign different penalties to various types of misclassifications
# Custom Loss Matrix: TP=0, FN=5, FP=1, TN=0
loss_matrix <- matrix(c(0, 5, 1, 0), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("yes", "no"),
Predicted = c("yes", "no")))
# Print loss matrix to verify correct setup
print(loss_matrix)
# Use "rpart" instead of "tree" library in order to use custom loss matrices
# Fit the tree on train(?) data with loss matrix
fit_tree_with_loss <- rpart(y ~ ., data = train, method = "class",
parms = list(loss = loss_matrix))
summary(fit_tree_with_loss)
# Make predictions on the test data
pred_test_loss <- predict(fit_tree_with_loss, newdata = test, type = "class")
# Confusion matrix based on test data
confusion_matrix1 <- table(True = test$y, Predicted = pred_test_loss)
print(confusion_matrix1)
print(confusion_matrix)
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binominal")
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logit, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
tpr_logistic[1:10]
tpr_logistic[1567:1569]
tpr_logistic[167:169]
tpr_logistic[1:20]
fpr_logistic[1:20]
tpr_logistic
tpr_logistic
fpr_logistic[1:20]
tpr_tree
fpr_tree
tpr_logistic
fpr_logistic[1:20]
tpr_tree
fpr_tree
tpr_logistic
fpr_logistic[1:20]
tpr_tree
fpr_tree
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
tpr_logistic
fpr_logistic[1:20]
tpr_tree
fpr_tree
# PLot ROC curve for both models
plot(fpr_tree, tpr_tree, type = "l", col = "red", lwd = 2,
xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curve", xlim = c(0, 1), ylim = c(0, 1))
lines(fpr_logit, tpr_logit, col = "blue", lwd = 2)
# PLot ROC curve for both models
plot(fpr_tree, tpr_tree, type = "l", col = "red", lwd = 2,
xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curve", xlim = c(0, 1), ylim = c(0, 1))
lines(fpr_logistic, tpr_logistic, col = "blue", lwd = 2)
# PLot ROC curve for both models
plot(fpr_tree, tpr_tree, type = "l", col = "red", lwd = 2,
xlab = "False Positive Rate", ylab = "True Positive Rate",
main = "ROC Curve", xlim = c(0, 1), ylim = c(0, 1))
lines(fpr_logistic, tpr_logistic, col = "blue", lwd = 2)
# Add legend
legend("bottomright", legend = c("Decision Tree", "Logistic Regression"),
col = c("red", "blue"), lwd = 2)
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
#### TASK 2.6 - Optimal Tree & Logistic Regression ####
# Find probabilities of predicting y = 'yes' --> Compare with different thresholds and classify -->
# --> Compute TPR & FPR for each threshold
# FIt a logistic regression model
fit_logistic <-  glm(y ~ ., data = train, family = "binomial")
# Predict probabilities on test data
# type = "response" will give predicted PROBABILITIES for y = 'yes'
prob_logistic <- predict(fit_logistic, newdata = test, type = "response")
# type = "vector" will give predicted probabilities for each class, select y = 'yes' using [, "yes"]
prob_tree <- predict(optimalTree, newdata = test, type = "vector")[, "yes"]
# Define thresholds
thresholds <- seq(0.05, 0.95, by = 0.05)
# Initialize vectors to store TPR and FPR values for both models
tpr_tree <- numeric(length(thresholds)) # Array with equal amount of spots as number of thresholds
fpr_tree <- numeric(length(thresholds))
tpr_logistic <- numeric(length(thresholds))
fpr_logistic <- numeric(length(thresholds))
# Function to calculate TPR = True Positive Rate & FPR = False Positive Rates
compute_tpr_fpr <- function(probabilities, actuals, threshold) {
predicted <- ifelse(probabilities > threshold, "yes", "no")
# Confusion matrix
confusion_matrix <- table(True = actuals, Predicted = predicted)
print(confusion_matrix)
TP <- confusion_matrix["yes", "yes"] # True Positive.
TN <- confusion_matrix["no", "no"] # True Negative.
FP <- confusion_matrix["no", "yes"] # False Positive
FN <- confusion_matrix["yes", "no"] # False Negative
# Compute TPR and FPR
TPR <- TP / (TP + FN)  # True Positive Rate (Sensitivity = Recall)
FPR <- FP / (FP + TN)  # False Positive Rate (1 - Specificity)
return(c(TPR = TPR, FPR = FPR))
}
# Loop through each threshold and compute TPR and FPR for bOTh models
for (i in 1:length(thresholds)) {
# For Decision Tree
tpr_fpr_tree <- compute_tpr_fpr(prob_tree, test$y, thresholds[i])
tpr_tree[i] <- tpr_fpr_tree[1]
fpr_tree[i] <- tpr_fpr_tree[2]
# For the Logistic Regression
tpr_fpr_logistic <- compute_tpr_fpr(prob_logistic, test$y, thresholds[i])
tpr_logistic[i] <- tpr_fpr_logistic[1]
fpr_logistic[i] <- tpr_fpr_logistic[2]
}
